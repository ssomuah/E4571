{"nbformat_minor": 1, "nbformat": 4, "metadata": {"language_info": {"pygments_lexer": "scala", "file_extension": ".scala", "name": "scala", "version": "2.11.8", "codemirror_mode": "text/x-scala", "mimetype": "text/x-scala"}, "kernelspec": {"name": "apache_toree_scala", "language": "scala", "display_name": "Apache Toree - Scala"}, "anaconda-cloud": {}}, "cells": [{"cell_type": "code", "source": "val bs = spark\nimport bs.implicits._\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.ml.recommendation.{ALS,ALSModel}\nimport org.apache.spark.ml.feature.StringIndexer\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\nimport org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\nimport org.apache.log4j.{Level, Logger}\nimport org.apache.spark.sql.types.{StructType, StructField, StringType, IntegerType};", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "Waiting for a Spark session to start..."}}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "bs = org.apache.spark.sql.SparkSession@41cf1731\n"}}, {"metadata": {}, "execution_count": 1, "output_type": "execute_result", "data": {"text/html": "<ul>\n<li><a href=\"Some(http://ip-172-31-17-11.us-west-2.compute.internal:4040)\" target=\"new_tab\">Spark UI: application_1513407638949_0006</a></li>\n</ul>", "text/plain": "Spark application_1513407638949_0006: Some(http://ip-172-31-17-11.us-west-2.compute.internal:4040)"}}], "execution_count": 1}, {"cell_type": "markdown", "source": "# Introduction\n\nIn the second part of this project we would like to make our recommendations usings a model built with Spark.\n\nOnce again our aim is to recommend books to users. To do this we will train a model on the dataset of books available to us. Make predictions for how users would rate books they have not rated, and then the most highly rated books they have not read can be recommended to them.\n\nThe rationale for using spark is that it will achieve better peformance on large datasets. The python implementation only used the top .001% percent of the books available in the dataset. With spark we expect to be able to increase the size of the dataset without significant performance penalties.\n\n", "metadata": {}}, {"cell_type": "markdown", "source": "# Dataset\n\nThe dataset is the same book crossing dataset, using only explicit ratings.", "metadata": {}}, {"cell_type": "code", "source": "//For switching between local and AWS deployments\nval prepend =\"s3://colon/E4751/\"\n//val prepend =\"\"", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "prepend = s3://colon/E4751/\n"}}, {"metadata": {}, "execution_count": 2, "output_type": "execute_result", "data": {"text/plain": "s3://colon/E4751/"}}], "execution_count": 2}, {"cell_type": "code", "source": "//This is super important to know\nspark.version", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "execution_count": 3, "output_type": "execute_result", "data": {"text/plain": "2.2.0"}}], "execution_count": 3}, {"cell_type": "code", "source": "val desc_file = \"E4751/BX-Books.csv\"\n\nval ratings_file = \"E4751/BX-Book-Ratings.csv\"", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "desc_file = E4751/BX-Books.csv\nratings_file = E4751/BX-Book-Ratings.csv\n"}}, {"metadata": {}, "execution_count": 4, "output_type": "execute_result", "data": {"text/plain": "E4751/BX-Book-Ratings.csv"}}], "execution_count": 4}, {"cell_type": "code", "source": "//Create a schema for the csv to save reading the file twice to infer the schema\nval ratings_schema = StructType(Array(\n    StructField(\"User-ID\", IntegerType, true),\n    StructField(\"ISBN\", StringType, true),\n    StructField(\"Book-Rating\", IntegerType, true)))\n", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "ratings_schema = StructType(StructField(User-ID,IntegerType,true), StructField(ISBN,StringType,true), StructField(Book-Rating,IntegerType,true))\n"}}, {"metadata": {}, "execution_count": 5, "output_type": "execute_result", "data": {"text/plain": "StructType(StructField(User-ID,IntegerType,true), StructField(ISBN,StringType,true), StructField(Book-Rating,IntegerType,true))"}}], "execution_count": 5}, {"cell_type": "code", "source": "val df = spark.read.\n    option(\"sep\",\";\").\n    option(\"mode\",\"FAILFAST\").\n    option(\"header\",true).\n    option(\"encoding\",\"IBM850\").\n    schema(ratings_schema).\n    csv(ratings_file)", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "df = [User-ID: int, ISBN: string ... 1 more field]\n"}}, {"metadata": {}, "execution_count": 6, "output_type": "execute_result", "data": {"text/plain": "[User-ID: int, ISBN: string ... 1 more field]"}}], "execution_count": 6}, {"cell_type": "code", "source": "//Sanity check on the data\ndf.show(5)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+----------+-----------+\n|User-ID|      ISBN|Book-Rating|\n+-------+----------+-----------+\n| 276725|034545104X|          0|\n| 276726|0155061224|          5|\n| 276727|0446520802|          0|\n| 276729|052165615X|          3|\n| 276729|0521795028|          6|\n+-------+----------+-----------+\nonly showing top 5 rows\n\n"}], "execution_count": 7}, {"cell_type": "code", "source": "val rows = df.count()\nprintln(\"we have %d rows\".format(rows))", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "we have 1149780 rows                                                            \n"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "rows = 1149780\n"}}, {"metadata": {}, "execution_count": 8, "output_type": "execute_result", "data": {"text/plain": "1149780"}}], "execution_count": 8}, {"cell_type": "code", "source": "val unique_rows = df.dropDuplicates(Array(\"User-ID\",\"ISBN\")).count()\nval duplicates = rows - unique_rows\n\nprintln(\"we have %d duplicate rows\".format(duplicates))", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "we have 0 duplicate rows                                                        \n"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "unique_rows = 1149780\nduplicates = 0\n"}}, {"metadata": {}, "execution_count": 9, "output_type": "execute_result", "data": {"text/plain": "0"}}], "execution_count": 9}, {"cell_type": "code", "source": "//We're using explicit ratings so only greater than 0\nval df_explicit = df.filter($\"Book-Rating\">0)", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "df_explicit = [User-ID: int, ISBN: string ... 1 more field]\n"}}, {"metadata": {}, "execution_count": 10, "output_type": "execute_result", "data": {"text/plain": "[User-ID: int, ISBN: string ... 1 more field]"}}], "execution_count": 10}, {"cell_type": "code", "source": "df_explicit.show(5)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+----------+-----------+\n|User-ID|      ISBN|Book-Rating|\n+-------+----------+-----------+\n| 276726|0155061224|          5|\n| 276729|052165615X|          3|\n| 276729|0521795028|          6|\n| 276736|3257224281|          8|\n| 276737|0600570967|          6|\n+-------+----------+-----------+\nonly showing top 5 rows\n\n"}], "execution_count": 11}, {"cell_type": "code", "source": "// a quick check on what the data looks like\nval unique_users = df_explicit.select(\"User-ID\").distinct().count()\nval unique_books = df_explicit.select(\"ISBN\").distinct().count()\nval total_ratings = df_explicit.count()\n", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 13:=====================>                                    (3 + 5) / 8]"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "unique_users = 77805\nunique_books = 185973\ntotal_ratings = 433671\n"}}, {"metadata": {}, "execution_count": 12, "output_type": "execute_result", "data": {"text/plain": "433671"}}], "execution_count": 12}, {"cell_type": "code", "source": "println(\"The number of unique users is %d\".format(unique_users))\nprintln(\"The number of unique books is %d\".format(unique_books))\nprintln(\"The number of ratings is %d\".format(total_ratings))", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The number of unique users is 77805\nThe number of unique books is 185973\nThe number of ratings is 433671\n"}], "execution_count": 13}, {"cell_type": "code", "source": "//what do ratings look like\ndf_explicit.describe(\"Book-Rating\").show()", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 15:=============================>                            (4 + 4) / 8]+-------+------------------+\n|summary|       Book-Rating|\n+-------+------------------+\n|  count|            433671|\n|   mean| 7.601066246071331|\n| stddev|1.8437976309993231|\n|    min|                 1|\n|    max|                10|\n+-------+------------------+\n\n"}], "execution_count": 14}, {"cell_type": "code", "source": "//how many times books have been rated\ndf_explicit.groupBy(\"ISBN\").count().describe(\"count\").show()", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 18:===============================================>      (176 + 9) / 200]+-------+------------------+\n|summary|             count|\n+-------+------------------+\n|  count|            185973|\n|   mean|2.3319030181800584|\n| stddev| 6.834667418109391|\n|    min|                 1|\n|    max|               707|\n+-------+------------------+\n\n"}], "execution_count": 15}, {"cell_type": "code", "source": "//how many books have users rated\ndf_explicit.groupBy(\"User-ID\").count().describe(\"count\").show()", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 21:====================================================> (194 + 6) / 200]+-------+-----------------+\n|summary|            count|\n+-------+-----------------+\n|  count|            77805|\n|   mean|5.573819163292847|\n| stddev|44.00187870029838|\n|    min|                1|\n|    max|             8524|\n+-------+-----------------+\n\n"}], "execution_count": 16}, {"cell_type": "code", "source": "//Take a look at the distributions of \n//the number of times books have been rated\n//the number of books users have rated \n//75th to 99th quantiles\n\nval desired_quantiles= (.75 to .99 by.01).toArray\n//https://spark.apache.org/docs/2.0.2/api/java/org/apache/spark/sql/DataFrameStatFunctions.html#approxQuantile(java.lang.String,%20double[],%20double)\nval book_counts_quantile_values = df_explicit.groupBy(\"ISBN\").count().stat.approxQuantile(\"count\",desired_quantiles,0)\nval book_counts_quantile_map = (desired_quantiles zip book_counts_quantile_values).toMap\n", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 24:=====================================================>(199 + 1) / 200]"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "desired_quantiles = Array(0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.8200000000000001, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.9299999999999999, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99)\nbook_counts_quantile_values = Array(2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 5.0, 6.0, 6.0, 8.0, 10.0, 13.0, 22.0)\nbook_counts_quantile_map = Map(0.84 -> 3.0, 0.86 -> 3.0, 0.88 -> 3.0, 0.89 -> 3.0, 0.96 -> 8.0, 0.91 -> 4.0, 0.9299999999999999 -> 5.0, 0.8 -> 2.0, 0.99 -> 22.0, 0.75 -> 2.0, 0.78 -> 2.0, 0.81 -> 2.0, 0.87 -> 3.0, 0.79 -> 2.0, 0.77 -> 2.0, 0.98 -> 13.0, 0.83 -> 2.0, 0.85 -> 3.0, 0.76 -> 2.0, 0.9 -> 4.0, 0.94 -> 6.0, 0.92 -> 4.0, 0.97 -> 10.0, 0.95 -> 6...\n"}}, {"metadata": {}, "execution_count": 17, "output_type": "execute_result", "data": {"text/plain": "Map(0.84 -> 3.0, 0.86 -> 3.0, 0.88 -> 3.0, 0.89 -> 3.0, 0.96 -> 8.0, 0.91 -> 4.0, 0.9299999999999999 -> 5.0, 0.8 -> 2.0, 0.99 -> 22.0, 0.75 -> 2.0, 0.78 -> 2.0, 0.81 -> 2.0, 0.87 -> 3.0, 0.79 -> 2.0, 0.77 -> 2.0, 0.98 -> 13.0, 0.83 -> 2.0, 0.85 -> 3.0, 0.76 -> 2.0, 0.9 -> 4.0, 0.94 -> 6.0, 0.92 -> 4.0, 0.97 -> 10.0, 0.95 -> 6.0, 0.8200000000000001 -> 2.0)"}}], "execution_count": 17}, {"cell_type": "code", "source": "//quantiles for the number of times a book has been rated\nfor (i <- desired_quantiles.indices){\n    println(\"%f : %f\".format(desired_quantiles(i),book_counts_quantile_values(i)))\n}", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "0.750000 : 2.000000\n0.760000 : 2.000000\n0.770000 : 2.000000\n0.780000 : 2.000000\n0.790000 : 2.000000\n0.800000 : 2.000000\n0.810000 : 2.000000\n0.820000 : 2.000000\n0.830000 : 2.000000\n0.840000 : 3.000000\n0.850000 : 3.000000\n0.860000 : 3.000000\n0.870000 : 3.000000\n0.880000 : 3.000000\n0.890000 : 3.000000\n0.900000 : 4.000000\n0.910000 : 4.000000\n0.920000 : 4.000000\n0.930000 : 5.000000\n0.940000 : 6.000000\n0.950000 : 6.000000\n0.960000 : 8.000000\n0.970000 : 10.000000\n0.980000 : 13.000000\n0.990000 : 22.000000\n"}], "execution_count": 18}, {"cell_type": "code", "source": "val user_counts_quantile_values = df_explicit.groupBy(\"User-ID\").count().stat.approxQuantile(\"count\",desired_quantiles,0)\nval user_counts_quantile_map = (desired_quantiles zip user_counts_quantile_values).toMap\n", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 26:=====================================================>(197 + 3) / 200]"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "user_counts_quantile_values = Array(3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 6.0, 6.0, 7.0, 7.0, 8.0, 9.0, 10.0, 11.0, 13.0, 16.0, 19.0, 23.0, 30.0, 44.0, 74.0)\nuser_counts_quantile_map = Map(0.84 -> 5.0, 0.86 -> 6.0, 0.88 -> 7.0, 0.89 -> 8.0, 0.96 -> 23.0, 0.91 -> 10.0, 0.9299999999999999 -> 13.0, 0.8 -> 4.0, 0.99 -> 74.0, 0.75 -> 3.0, 0.78 -> 4.0, 0.81 -> 4.0, 0.87 -> 7.0, 0.79 -> 4.0, 0.77 -> 3.0, 0.98 -> 44.0, 0.83 -> 5.0, 0.85 -> 6.0, 0.76 -> 3.0, 0.9 -> 9.0, 0.94 -> 16.0, 0.92 -> 11.0, 0.97 -> 30.0, 0.95 -> 19.0, 0.8200000000000001 -> 5.0)\n"}}, {"metadata": {}, "execution_count": 19, "output_type": "execute_result", "data": {"text/plain": "Map(0.84 -> 5.0, 0.86 -> 6.0, 0.88 -> 7.0, 0.89 -> 8.0, 0.96 -> 23.0, 0.91 -> 10.0, 0.9299999999999999 -> 13.0, 0.8 -> 4.0, 0.99 -> 74.0, 0.75 -> 3.0, 0.78 -> 4.0, 0.81 -> 4.0, 0.87 -> 7.0, 0.79 -> 4.0, 0.77 -> 3.0, 0.98 -> 44.0, 0.83 -> 5.0, 0.85 -> 6.0, 0.76 -> 3.0, 0.9 -> 9.0, 0.94 -> 16.0, 0.92 -> 11.0, 0.97 -> 30.0, 0.95 -> 19.0, 0.8200000000000001 -> 5.0)"}}], "execution_count": 19}, {"cell_type": "code", "source": "//quantiles for the number of books a user has rated\nfor (i <- desired_quantiles.indices){\n    println(\"%f : %f\".format(desired_quantiles(i),user_counts_quantile_values(i)))\n}", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "0.750000 : 3.000000\n0.760000 : 3.000000\n0.770000 : 3.000000\n0.780000 : 4.000000\n0.790000 : 4.000000\n0.800000 : 4.000000\n0.810000 : 4.000000\n0.820000 : 5.000000\n0.830000 : 5.000000\n0.840000 : 5.000000\n0.850000 : 6.000000\n0.860000 : 6.000000\n0.870000 : 7.000000\n0.880000 : 7.000000\n0.890000 : 8.000000\n0.900000 : 9.000000\n0.910000 : 10.000000\n0.920000 : 11.000000\n0.930000 : 13.000000\n0.940000 : 16.000000\n0.950000 : 19.000000\n0.960000 : 23.000000\n0.970000 : 30.000000\n0.980000 : 44.000000\n0.990000 : 74.000000\n"}], "execution_count": 20}, {"cell_type": "code", "source": "//Create a schema for the csv to save reading the file twice to infer the schema\nval ratings_schema = StructType(Array(\n    StructField(\"ISBN\", StringType, true),\n    StructField(\"Book-Title\", StringType, true),\n    StructField(\"Book-Author\", StringType, true),\n    StructField(\"Year-Of-Publication\", IntegerType, true),\n    StructField(\"Publisher\", StringType, true),\n    StructField(\"Image-URL-S\", StringType, true),\n    StructField(\"Image-URL-M\", StringType, true),\n    StructField(\"Image-URL-L\", StringType, true)))", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "ratings_schema = StructType(StructField(ISBN,StringType,true), StructField(Book-Title,StringType,true), StructField(Book-Author,StringType,true), StructField(Year-Of-Publication,IntegerType,true), StructField(Publisher,StringType,true), StructField(Image-URL-S,StringType,true), StructField(Image-URL-M,StringType,true), StructField(Image-URL-L,StringType,true))\n"}}, {"metadata": {}, "execution_count": 21, "output_type": "execute_result", "data": {"text/plain": "StructType(StructField(ISBN,StringType,true), StructField(Book-Title,StringType,true), StructField(Book-Author,StringType,true), StructField(Year-Of-Publication,IntegerType,true), StructField(Publisher,StringType,true), StructField(Image-URL-S,StringType,true), StructField(Image-URL-M,StringType,true), StructField(Image-URL-L,StringType,true))"}}], "execution_count": 21}, {"cell_type": "code", "source": "//Can we get some idea of what the most frequently rated books are?\n//Can we see what the most positively rated book is \n\n//read in a dataset of book titles\nval df_desc = spark.read.option(\"sep\",\";\").\n    option(\"header\",true).\n    option(\"encoding\",\"IBM850\").\n    option(\"escape\",\"\\\\\").\n    schema(ratings_schema).\n    csv(desc_file)", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "df_desc = [ISBN: string, Book-Title: string ... 6 more fields]\n"}}, {"metadata": {}, "execution_count": 22, "output_type": "execute_result", "data": {"text/plain": "[ISBN: string, Book-Title: string ... 6 more fields]"}}], "execution_count": 22}, {"cell_type": "code", "source": "//quick sanity check\n\ndf_desc.show(3)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n|      ISBN|          Book-Title|         Book-Author|Year-Of-Publication|           Publisher|         Image-URL-S|         Image-URL-M|         Image-URL-L|\n+----------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n|0195153448| Classical Mythology|  Mark P. O. Morford|               2002|Oxford University...|http://images.ama...|http://images.ama...|http://images.ama...|\n|0002005018|        Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|http://images.ama...|http://images.ama...|http://images.ama...|\n|0060973129|Decision in Normandy|        Carlo D'Este|               1991|     HarperPerennial|http://images.ama...|http://images.ama...|http://images.ama...|\n+----------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 3 rows\n\n"}], "execution_count": 23}, {"cell_type": "code", "source": "//merge the ratings and book descriptions\n\nval df_merged = df_explicit.join(df_desc,Array(\"ISBN\"))\ndf_merged.cache", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "df_merged = [ISBN: string, User-ID: int ... 8 more fields]\n"}}, {"metadata": {}, "execution_count": 24, "output_type": "execute_result", "data": {"text/plain": "[ISBN: string, User-ID: int ... 8 more fields]"}}], "execution_count": 24}, {"cell_type": "code", "source": "//what's the most frequently rated book\n\nval ratings_count = df_merged.groupBy(\"ISBN\").count().orderBy($\"count\".desc)\nratings_count.cache\nratings_count.show(10,false)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 33:=================================================>    (185 + 4) / 200]+----------+-----+\n|ISBN      |count|\n+----------+-----+\n|0316666343|707  |\n|0971880107|581  |\n|0385504209|487  |\n|0312195516|383  |\n|0060928336|320  |\n|059035342X|313  |\n|0142001740|307  |\n|0446672211|295  |\n|044023722X|281  |\n|0452282152|278  |\n+----------+-----+\nonly showing top 10 rows\n\n"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "ratings_count = [ISBN: string, count: bigint]\n"}}, {"metadata": {}, "execution_count": 25, "output_type": "execute_result", "data": {"text/plain": "[ISBN: string, count: bigint]"}}], "execution_count": 25}, {"cell_type": "code", "source": "val users_count = df_merged.groupBy(\"User-ID\").count()\nusers_count.cache\nusers_count.show(3)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 37:===================================================>  (192 + 4) / 200]+-------+-----+\n|User-ID|count|\n+-------+-----+\n| 161234|   18|\n| 178199|   94|\n|  41751|    6|\n+-------+-----+\nonly showing top 3 rows\n\n"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "users_count = [User-ID: int, count: bigint]\n"}}, {"metadata": {}, "execution_count": 26, "output_type": "execute_result", "data": {"text/plain": "[User-ID: int, count: bigint]"}}], "execution_count": 26}, {"cell_type": "code", "source": "//The books with the highest average rating\nval avg_ratings = df_merged.groupBy(\"ISBN\").avg(\"Book-Rating\").withColumnRenamed(\"avg(Book-Rating)\",\"avg_rating\").orderBy($\"avg_rating\".desc)\navg_ratings.show(10,false)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 41:============================================>         (166 + 5) / 200]+----------+----------+\n|ISBN      |avg_rating|\n+----------+----------+\n|0140096655|10.0      |\n|0226752275|10.0      |\n|0140144196|10.0      |\n|0006717047|10.0      |\n|0140165886|10.0      |\n|0131453580|10.0      |\n|0192827529|10.0      |\n|0226504646|10.0      |\n|0062511327|10.0      |\n|0195084829|10.0      |\n+----------+----------+\nonly showing top 10 rows\n\n"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "avg_ratings = [ISBN: string, avg_rating: double]\n"}}, {"metadata": {}, "execution_count": 27, "output_type": "execute_result", "data": {"text/plain": "[ISBN: string, avg_rating: double]"}}], "execution_count": 27}, {"cell_type": "code", "source": "val combined_rating = avg_ratings.join(ratings_count,Array(\"ISBN\")) ", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "combined_rating = [ISBN: string, avg_rating: double ... 1 more field]\n"}}, {"metadata": {}, "execution_count": 28, "output_type": "execute_result", "data": {"text/plain": "[ISBN: string, avg_rating: double ... 1 more field]"}}], "execution_count": 28}, {"cell_type": "code", "source": "//the most frequently rated books and their average rating \ncombined_rating.orderBy($\"count\".desc).show(10,false)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 52:=====================================================>(182 + 3) / 185]+----------+------------------+-----+\n|ISBN      |avg_rating        |count|\n+----------+------------------+-----+\n|0316666343|8.185289957567186 |707  |\n|0971880107|4.3907056798623065|581  |\n|0385504209|8.435318275154003 |487  |\n|0312195516|8.182767624020888 |383  |\n|0060928336|7.8875            |320  |\n|059035342X|8.939297124600639 |313  |\n|0142001740|8.452768729641694 |307  |\n|0446672211|8.142372881355932 |295  |\n|044023722X|7.338078291814947 |281  |\n|0452282152|7.982014388489208 |278  |\n+----------+------------------+-----+\nonly showing top 10 rows\n\n"}], "execution_count": 29}, {"cell_type": "code", "source": "//the highest rated books and their number of times rated\ncombined_rating.orderBy($\"avg_rating\".desc).show(10,false)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+----------+-----+                                                   \n|ISBN      |avg_rating|count|\n+----------+----------+-----+\n|0310385709|10.0      |2    |\n|0307124568|10.0      |1    |\n|0192834096|10.0      |1    |\n|014200135X|10.0      |1    |\n|0140109269|10.0      |1    |\n|0140512047|10.0      |1    |\n|0140447113|10.0      |1    |\n|0060803312|10.0      |2    |\n|0060173890|10.0      |1    |\n|0060595264|10.0      |1    |\n+----------+----------+-----+\nonly showing top 10 rows\n\n"}], "execution_count": 30}, {"cell_type": "markdown", "source": "We filter the ratings so that we are only looking at the most popular books and have users that have rated at least 2 books. \nTo compare with the previous python implementation we will use the same cutoff values", "metadata": {}}, {"cell_type": "code", "source": "//based on the qunatiles computed earlier these will be the cutoffs for filtering the ratings records\n//books with more than 90 ratings\n//users with more than 1 book rated\nval book_quantile = 90\n\nval user_quantile = 1\n", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "book_quantile = 90\nuser_quantile = 1\n"}}, {"metadata": {}, "execution_count": 31, "output_type": "execute_result", "data": {"text/plain": "1"}}], "execution_count": 31}, {"cell_type": "code", "source": "val top_percentile_books = df_merged.join(ratings_count,Seq(\"ISBN\")).\nfilter($\"count\">book_quantile).\ndrop(\"count\")\n\nval top_percentile_books_user = top_percentile_books.join(top_percentile_books.groupBy(\"User-ID\").count(),Seq(\"User-ID\")).\nfilter($\"count\">user_quantile).\ndrop(\"count\")\n\nval temp = top_percentile_books_user\n\n", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "top_percentile_books = [ISBN: string, User-ID: int ... 8 more fields]\ntop_percentile_books_user = [User-ID: int, ISBN: string ... 8 more fields]\ntemp = [User-ID: int, ISBN: string ... 8 more fields]\n"}}, {"metadata": {}, "execution_count": 32, "output_type": "execute_result", "data": {"text/plain": "[User-ID: int, ISBN: string ... 8 more fields]"}}], "execution_count": 32}, {"cell_type": "code", "source": "temp.cache", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "execution_count": 33, "output_type": "execute_result", "data": {"text/plain": "[User-ID: int, ISBN: string ... 8 more fields]"}}], "execution_count": 33}, {"cell_type": "code", "source": "//check that every book has at least one rating after filtering on users\ntemp.groupBy(\"ISBN\").count().filter($\"count\"===0).show()", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 72:=====================================================>(198 + 2) / 200]+----+-----+\n|ISBN|count|\n+----+-----+\n+----+-----+\n\n"}], "execution_count": 34}, {"cell_type": "code", "source": "val N = temp.select(\"User-ID\").distinct().count()\nprintln(\"The number of unique users is in the trimmed dataset is  %d\".format(N))\n\nval M = temp.select(\"ISBN\").distinct().count()\nprintln(\"The number of unique books in the trimmed dataset is %d\".format(M))\nprintln(\"The number of ratings in the trimmed dataset is %d\".format(temp.count()))\n", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 102:==================================================>  (192 + 7) / 200]The number of unique users is in the trimmed dataset is  4328\nThe number of unique books in the trimmed dataset is 178                        \nThe number of ratings in the trimmed dataset is 17195\n"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "N = 4328\nM = 178\n"}}, {"metadata": {}, "execution_count": 35, "output_type": "execute_result", "data": {"text/plain": "178"}}], "execution_count": 35}, {"cell_type": "code", "source": "//generate new ids for books and users that are consecutive integers\nval uid_indexer = new StringIndexer().\n    setInputCol(\"User-ID\").\n    setOutputCol(\"uid\")\n    \nval bid_indexer = new StringIndexer().\n    setInputCol(\"ISBN\").\n    setOutputCol(\"bid\")\n      \nval uid_indexer_fitted = uid_indexer.fit(df_merged)\n\nval bid_indexer_fitted = bid_indexer.fit(df_merged)\n\nval t1 = uid_indexer_fitted.transform(temp)\n\nval t2 = bid_indexer_fitted.transform(t1)\n\nval data = t2\n\n", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 124:===============================================>    (184 + 10) / 200]"}, {"metadata": {}, "execution_count": 36, "output_type": "execute_result", "data": {"text/plain": "[User-ID: int, ISBN: string ... 10 more fields]"}}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "uid_indexer = strIdx_99696053c4b8\nbid_indexer = strIdx_787076725cf2\nuid_indexer_fitted = strIdx_99696053c4b8\nbid_indexer_fitted = strIdx_787076725cf2\nt1 = [User-ID: int, ISBN: string ... 9 more fields]\nt2 = [User-ID: int, ISBN: string ... 10 more fields]\ndata = [User-ID: int, ISBN: string ... 10 more fields]\n"}}], "execution_count": 36}, {"cell_type": "code", "source": "//train test split \nval Array(training, test) = data.randomSplit(Array(0.8, 0.2))", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "training = [User-ID: int, ISBN: string ... 10 more fields]\ntest = [User-ID: int, ISBN: string ... 10 more fields]\n"}}, {"metadata": {}, "execution_count": 37, "output_type": "execute_result", "data": {"text/plain": "[User-ID: int, ISBN: string ... 10 more fields]"}}], "execution_count": 37}, {"cell_type": "markdown", "source": "# Baseline model", "metadata": {}}, {"cell_type": "markdown", "source": "Before we start using collaborative filtering  we first implement a baseline model that simply uses the average book rating of the dataset as the predicted rating for a book.  ", "metadata": {}}, {"cell_type": "code", "source": "//I suspect there is some inefficency in the way in which the mean is calculated and distributed to workers\nval avg_rating = training.select(mean($\"Book-Rating\")).head().getDouble(0)\n\nval rmse_baseline = math.sqrt(test.select(\"Book-Rating\").as[(Double)].rdd.map(x=>math.pow(avg_rating-x,2)).mean)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 135:===================================================> (196 + 4) / 200]"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "avg_rating = 7.9347084029341275\nrmse_baseline = 1.7784020259751816\n"}}, {"metadata": {}, "execution_count": 38, "output_type": "execute_result", "data": {"text/plain": "1.7784020259751816"}}], "execution_count": 38}, {"cell_type": "code", "source": "println(\"RMSE for baseline model is %f\".format(rmse_baseline))", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "RMSE for baseline model is 1.778402\n"}], "execution_count": 39}, {"cell_type": "code", "source": "//a regression evaluator that does rmse\nval evaluator = new RegressionEvaluator().\n    setMetricName(\"rmse\").\n    setLabelCol(\"Book-Rating\").\n    setPredictionCol(\"prediction\")", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "evaluator = regEval_25d7d1c9a5b9\n"}}, {"metadata": {}, "execution_count": 40, "output_type": "execute_result", "data": {"text/plain": "regEval_25d7d1c9a5b9"}}], "execution_count": 40}, {"cell_type": "code", "source": "val als = new ALS().\n    setMaxIter(10).\n    setUserCol(\"uid\").\n    setItemCol(\"bid\").\n    setRatingCol(\"Book-Rating\").\n    setColdStartStrategy(\"drop\")\n    \n\nval implicit_als = new ALS().\n    setMaxIter(10).\n    setUserCol(\"uid\").\n    setItemCol(\"bid\").\n    setRatingCol(\"Book-Rating\").\n    setImplicitPrefs(true).\n    setColdStartStrategy(\"drop\")\n\nval nn_als = new ALS().\n    setMaxIter(10).\n    setUserCol(\"uid\").\n    setItemCol(\"bid\").\n    setRatingCol(\"Book-Rating\").\n    setColdStartStrategy(\"drop\").\n    setNonnegative(true)\n    \n    \n", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "als = als_cc7eb7096bc9\nimplicit_als = als_40414a6ea62c\nnn_als = als_97c85689df9f\n"}}, {"metadata": {}, "execution_count": 52, "output_type": "execute_result", "data": {"text/plain": "als_97c85689df9f"}}], "execution_count": 52}, {"cell_type": "code", "source": "val als_rmse = evaluator.evaluate(als.fit(training).transform(test))\nval implicit_als_rmse = evaluator.evaluate(implicit_als.fit(training).transform(test))\nval nn_als_rmse = evaluator.evaluate(nn_als.fit(training).transform(test))\nprintln(\"RMSE for explicit als is %f\".format(als_rmse))\nprintln(\"RMSE for implicit als is %f\".format(implicit_als_rmse))\nprintln(\"RMSE for nonnegative explicit als is %f\".format(nn_als_rmse))", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "RMSE for explicit als is 2.920287                                               \nRMSE for implicit als is 7.953853\nRMSE for nonnegative explicit als is 2.509765\n"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "als_rmse = 2.920286503259058\nimplicit_als_rmse = 7.953852766799263\nnn_als_rmse = 2.509765207804227\n"}}, {"metadata": {}, "execution_count": 53, "output_type": "execute_result", "data": {"text/plain": "2.509765207804227"}}], "execution_count": 53}, {"cell_type": "markdown", "source": "# Improvements\n\nWe want to illustrate some of the problems with the dataset we are working with. \nHere we see that for the same book it appears under several different ISBNS. Even ignoring audio books and other formats, we still have several versions.  \nThis does not even consider the same book in different languages.  \nThere is one easy correction we can make, that is to either uppercase or lowercase all the ISBNS to reduce unify those instances where books are split accross ISBNs because of that. \n", "metadata": {}}, {"cell_type": "code", "source": "val cols = Seq(\"ISBN\",\"Book-Title\")\ndf_merged.dropDuplicates(\"ISBN\").filter($\"Book-Title\" rlike \".*Harry Potter and the Sorcerer's Stone.*\").select(cols.map(x=>col(x)):_*).show(100,false)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+----------------------------------------------------------------+   \n|ISBN      |Book-Title                                                      |\n+----------+----------------------------------------------------------------+\n|0807281956|Harry Potter and the Sorcerer's Stone (Book 1 Audio CD)         |\n|1594130000|Harry Potter and the Sorcerer's Stone                           |\n|059035342x|Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))|\n|0807281751|Harry Potter and the Sorcerer's Stone (Book 1, Audio)           |\n|043920352X|Harry Potter and the Sorcerer's Stone (Book 1)                  |\n|043936213X|Harry Potter and the Sorcerer's Stone (Book 1)                  |\n|043936213x|Harry Potter and the Sorcerer's Stone (Book 1)                  |\n|0590353403|Harry Potter and the Sorcerer's Stone (Book 1)                  |\n|0439294827|Harry Potter and the Sorcerer's Stone: A Deluxe Pop-up Book     |\n|0786222727|Harry Potter and the Sorcerer's Stone (Book 1, Large Print)     |\n|0439286239|Harry Potter and the Sorcerer's Stone Movie Poster Book         |\n|059035342X|Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))|\n+----------+----------------------------------------------------------------+\n\n"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "cols = List(ISBN, Book-Title)\n"}}, {"metadata": {}, "execution_count": 43, "output_type": "execute_result", "data": {"text/plain": "List(ISBN, Book-Title)"}}], "execution_count": 43}, {"cell_type": "code", "source": "//make a new df unified and use that from now on with ISBN transformed to uppercase\n//count unique books again after doing that\nval df_unified =df_merged.withColumn(\"ISBN\", upper(col(\"ISBN\")));", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "df_unified = [ISBN: string, User-ID: int ... 8 more fields]\n"}}, {"metadata": {}, "execution_count": 44, "output_type": "execute_result", "data": {"text/plain": "[ISBN: string, User-ID: int ... 8 more fields]"}}], "execution_count": 44}, {"cell_type": "code", "source": "df_unified.dropDuplicates(\"ISBN\").filter($\"Book-Title\" rlike \".*Harry Potter and the Sorcerer's Stone.*\").select(cols.map(x=>col(x)):_*).show(100,false)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+----------------------------------------------------------------+   \n|ISBN      |Book-Title                                                      |\n+----------+----------------------------------------------------------------+\n|0807281956|Harry Potter and the Sorcerer's Stone (Book 1 Audio CD)         |\n|1594130000|Harry Potter and the Sorcerer's Stone                           |\n|0807281751|Harry Potter and the Sorcerer's Stone (Book 1, Audio)           |\n|043920352X|Harry Potter and the Sorcerer's Stone (Book 1)                  |\n|043936213X|Harry Potter and the Sorcerer's Stone (Book 1)                  |\n|0590353403|Harry Potter and the Sorcerer's Stone (Book 1)                  |\n|0439294827|Harry Potter and the Sorcerer's Stone: A Deluxe Pop-up Book     |\n|0786222727|Harry Potter and the Sorcerer's Stone (Book 1, Large Print)     |\n|0439286239|Harry Potter and the Sorcerer's Stone Movie Poster Book         |\n|059035342X|Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))|\n+----------+----------------------------------------------------------------+\n\n"}], "execution_count": 45}, {"cell_type": "code", "source": "//count the number of distinct books again\n\nprintln(\"The number of unique books is now %d\".format(df_unified.select(\"ISBN\").distinct().count()))", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The number of unique books is now 149723                                        \n"}], "execution_count": 46}, {"cell_type": "markdown", "source": "We've managed to reduce the number of unique books from  185,973 to 149,723.  \nAbout a 20% reduction.  \nMoving forward we will use this unified dataset", "metadata": {}}, {"cell_type": "code", "source": "//split into new train and test based on the unified dataset\nval top_percentile_books_unified = df_unified.join(ratings_count,Seq(\"ISBN\")).\nfilter($\"count\">book_quantile).\ndrop(\"count\")\n\nval top_percentile_books_user_unified = top_percentile_books_unified.join(top_percentile_books_unified.groupBy(\"User-ID\").count(),Seq(\"User-ID\")).\nfilter($\"count\">user_quantile).\ndrop(\"count\")\n\nval temp_2 = top_percentile_books_user_unified\n\nval t3 = uid_indexer_fitted.transform(temp_2)\n\nval t4 = bid_indexer_fitted.transform(t3)\n\nval data_unified = t4\n\ndata_unified.cache\n\nval model_cols = Seq(\"uid\",\"bid\",\"Book-Rating\")\n\nval Array(training_unified, test_unified) = data_unified.select(model_cols.map(x=>col(x)):_*).randomSplit(Array(0.8, 0.2))", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "top_percentile_books_unified = [ISBN: string, User-ID: int ... 8 more fields]\ntop_percentile_books_user_unified = [User-ID: int, ISBN: string ... 8 more fields]\ntemp_2 = [User-ID: int, ISBN: string ... 8 more fields]\nt3 = [User-ID: int, ISBN: string ... 9 more fields]\nt4 = [User-ID: int, ISBN: string ... 10 more fields]\ndata_unified = [User-ID: int, ISBN: string ... 10 more fields]\nmodel_cols = List(uid, bid, Book-Rating)\ntraining_unified = [uid: double, bid: double ... 1 more field]\n"}}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "test_unified: org.apache.spark.sql.Dataset[org....\n"}}, {"metadata": {}, "execution_count": 47, "output_type": "execute_result", "data": {"text/plain": "[uid: double, bid: double ... 1 more field]"}}], "execution_count": 47}, {"cell_type": "markdown", "source": "We will now tune the parameters of the models, by searching for optimal hyperparameters", "metadata": {}}, {"cell_type": "code", "source": "//gridsearch using cross validation to find parameters for regularization and rank\n\n//NOTE\n//gridsearching is incredibly time-intensive, even though the following code runs correctly it was not actually used\n//instead the default rank of 10 and regularisation 1\n\nval regs = Array(.01,1,10)\nval ranks = Array(2,6,10)\n\nval param_grid = new ParamGridBuilder().\n    addGrid(als.regParam,regs).\n    addGrid(als.rank,ranks).\n    build()\n\nval nn_param_grid = new ParamGridBuilder().\n    addGrid(nn_als.regParam,regs).\n    addGrid(nn_als.rank,ranks).\n    build()\n\nval implicit_param_grid = new ParamGridBuilder().\n    addGrid(implicit_als.regParam,regs).\n    addGrid(implicit_als.rank,ranks).\n    build()\n\nval cv = new CrossValidator().\n    setEstimator(als).\n    setEvaluator(evaluator).\n    setEstimatorParamMaps(param_grid).\n    setNumFolds(3) \n\nval nn_cv = new CrossValidator().\n    setEstimator(nn_als).\n    setEvaluator(evaluator).\n    setEstimatorParamMaps(nn_param_grid).\n    setNumFolds(3)\n\nval implicit_cv = new CrossValidator().\n    setEstimator(implicit_als).\n    setEvaluator(evaluator).\n    setEstimatorParamMaps(implicit_param_grid).\n    setNumFolds(3)", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "regs = Array(0.01, 1.0, 10.0)\nranks = Array(2, 6, 10)\nparam_grid = \nnn_param_grid = \n"}}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "Array({\n\tals_cc7eb7096bc9-rank: 2,\n\tals_cc7eb7096bc9-regParam: 0.01\n}, {\n\tals_cc7eb7096bc9-rank: 2,\n\tals_cc7eb7096bc9-regParam: 1.0\n}, {\n\tals_cc7eb7096bc9-rank: 2,\n\tals_cc7eb7096bc9-regParam: 10.0\n}, {\n\tals_cc7eb7096bc9-rank: 6,\n\tals_cc7eb7096bc9-regParam: 0.01\n}, {\n\tals_cc7eb7096bc9-rank: 6,\n\tals_cc7eb7096bc9-regParam: 1.0\n}, {\n\tals_cc7eb7096bc9-rank: 6,\n\tals_cc7eb7096bc9-regParam: 10.0\n}, {\n\tals_cc7eb7096bc9-rank: 10,\n\tals_cc7eb7096bc9-regParam: 0.01\n}, {\n\tals_cc7eb7096bc9-rank: 10,\n\tals_cc7eb7096bc9-regParam: 1.0\n}, {\n\tals_cc7eb7096bc9-rank: 10,\n\tals_cc7eb7096bc9-regParam: 10.0\n})\nArray({\n\ta...\n"}}, {"metadata": {}, "execution_count": 54, "output_type": "execute_result", "data": {"text/plain": "[{\n\tals_97c85689df9f-rank: 2,\n\tals_97c85689df9f-regParam: 0.01\n}, {\n\tals_97c85689df9f-rank: 2,\n\tals_97c85689df9f-regParam: 1.0\n}, {\n\tals_97c85689df9f-rank: 2,\n\tals_97c85689df9f-regParam: 10.0\n}, {\n\tals_97c85689df9f-rank: 6,\n\tals_97c85689df9f-regParam: 0.01\n}, {\n\tals_97c85689df9f-rank: 6,\n\tals_97c85689df9f-regParam: 1.0\n}, {\n\tals_97c85689df9f-rank: 6,\n\tals_97c85689df9f-regParam: 10.0\n}, {\n\tals_97c85689df9f-rank: 10,\n\tals_97c85689df9f-regParam: 0.01\n}, {\n\tals_97c85689df9f-rank: 10,\n\tals_97c85689df9f-regParam: 1.0\n}, {\n\tals_97c85689df9f-rank: 10,\n\tals_97c85689df9f-regParam: 10.0\n}]"}}], "execution_count": 54}, {"cell_type": "code", "source": "val cv_model = als.fit(training_unified)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 951:================>                                       (3 + 7) / 10]"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "cv_model = als_cc7eb7096bc9\n"}}, {"metadata": {}, "execution_count": 55, "output_type": "execute_result", "data": {"text/plain": "als_cc7eb7096bc9"}}], "execution_count": 55}, {"cell_type": "code", "source": "val nn_cv_model = nn_als.fit(training_unified)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 1027:=================================================>     (9 + 1) / 10][Stage 984:>                                                       (0 + 0) / 10]"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "nn_cv_model = als_97c85689df9f\n"}}, {"metadata": {}, "execution_count": 56, "output_type": "execute_result", "data": {"text/plain": "als_97c85689df9f"}}], "execution_count": 56}, {"cell_type": "code", "source": "val implicit_cv_model = implicit_als.fit(training_unified)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 1471:=================================================>     (9 + 1) / 10]"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "implicit_cv_model = als_40414a6ea62c\n"}}, {"metadata": {}, "execution_count": 57, "output_type": "execute_result", "data": {"text/plain": "als_40414a6ea62c"}}], "execution_count": 57}, {"cell_type": "code", "source": "val predictions = cv_model.transform(test_unified)\nval train_predictions = cv_model.transform(training_unified)\nval rmse = evaluator.evaluate(predictions)\nval train_rmse = evaluator.evaluate(train_predictions)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 1537:===================================================>(198 + 2) / 200]"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "predictions = [uid: double, bid: double ... 2 more fields]\ntrain_predictions = [uid: double, bid: double ... 2 more fields]\nrmse = 2.9177706075757435\ntrain_rmse = 0.3518713085472958\n"}}, {"metadata": {}, "execution_count": 58, "output_type": "execute_result", "data": {"text/plain": "0.3518713085472958"}}], "execution_count": 58}, {"cell_type": "code", "source": "val nn_predictions = nn_cv_model.transform(test_unified)\nval nn_train_predictions = nn_cv_model.transform(training_unified)\nval nn_rmse = evaluator.evaluate(nn_predictions)\nval nn_train_rmse = evaluator.evaluate(nn_train_predictions)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 1603:==================================================> (195 + 5) / 200]"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "nn_predictions = [uid: double, bid: double ... 2 more fields]\nnn_train_predictions = [uid: double, bid: double ... 2 more fields]\nnn_rmse = 2.541436381885685\nnn_train_rmse = 0.36550044872860676\n"}}, {"metadata": {}, "execution_count": 59, "output_type": "execute_result", "data": {"text/plain": "0.36550044872860676"}}], "execution_count": 59}, {"cell_type": "code", "source": "val implicit_predictions = implicit_cv_model.transform(test_unified)\nval implicit_train_predictions = implicit_cv_model.transform(training_unified)\nval implicit_rmse = evaluator.evaluate(implicit_predictions)\nval implicit_train_rmse = evaluator.evaluate(implicit_train_predictions)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 1669:===================================================>(199 + 1) / 200]"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "implicit_predictions = [uid: double, bid: double ... 2 more fields]\nimplicit_train_predictions = [uid: double, bid: double ... 2 more fields]\nimplicit_rmse = 7.912597543101461\nimplicit_train_rmse = 7.642094651564277\n"}}, {"metadata": {}, "execution_count": 60, "output_type": "execute_result", "data": {"text/plain": "7.642094651564277"}}], "execution_count": 60}, {"cell_type": "code", "source": "//Only used for grid searching\nval best_reg_param = cv_model.bestModel.parent.getParam(\"regParam\")\nval best_rank_param = cv_model.bestModel.parent.getParam(\"rank\")\nval best_param_map = cv_model.bestModel.parent.extractParamMap()\nval best_reg = best_param_map.get(best_reg_param).get.asInstanceOf[Double]\nval best_rank = best_param_map.get(best_rank_param).get.asInstanceOf[Int]", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "//Only used for grid searching\nval nn_best_reg_param = nn_cv_model.bestModel.parent.getParam(\"regParam\")\nval nn_best_rank_param = nn_cv_model.bestModel.parent.getParam(\"rank\")\nval nn_best_param_map = nn_cv_model.bestModel.parent.extractParamMap()\nval nn_best_reg = nn_best_param_map.get(nn_best_reg_param).get.asInstanceOf[Double]\nval nn_best_rank = nn_best_param_map.get(nn_best_rank_param).get.asInstanceOf[Int]", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "//Only used for grid searching\nval implicit_best_reg_param = implicit_cv_model.bestModel.parent.getParam(\"regParam\")\nval implicit_best_rank_param = implicit_cv_model.bestModel.parent.getParam(\"rank\")\nval implicit_best_param_map = implicit_cv_model.bestModel.parent.extractParamMap()\nval implicit_best_reg = implicit_best_param_map.get(implicit_best_reg_param).get.asInstanceOf[Double]\nval implicit_best_rank = implicit_best_param_map.get(implicit_best_rank_param).get.asInstanceOf[Int]", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "val model_df = List((\"explicit\",10,1,train_rmse,rmse),\n                   (\"implicit\",10,1,implicit_train_rmse,implicit_rmse),\n                   (\"explicit_nonnegative\",10,1,nn_train_rmse,nn_rmse)).\n    toDF(\"model_type\",\"rank\",\"regularization\",\"train_rmse\",\"test_rmse\")", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "model_df = [model_type: string, rank: int ... 3 more fields]\n"}}, {"metadata": {}, "execution_count": 61, "output_type": "execute_result", "data": {"text/plain": "[model_type: string, rank: int ... 3 more fields]"}}], "execution_count": 61}, {"cell_type": "code", "source": "model_df.show()", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+----+--------------+-------------------+------------------+\n|          model_type|rank|regularization|         train_rmse|         test_rmse|\n+--------------------+----+--------------+-------------------+------------------+\n|            explicit|  10|             1| 0.3518713085472958|2.9177706075757435|\n|            implicit|  10|             1|  7.642094651564277| 7.912597543101461|\n|explicit_nonnegative|  10|             1|0.36550044872860676| 2.541436381885685|\n+--------------------+----+--------------+-------------------+------------------+\n\n"}], "execution_count": 62}, {"cell_type": "code", "source": "//save the dataframe of results\nmodel_df.coalesce(1).write.option(\"header\",true).mode(\"overwrite\").csv(prepend+\"output\")", "metadata": {"trusted": true}, "outputs": [], "execution_count": 63}, {"cell_type": "code", "source": "//save a copy of the model in case we want to use it without refitting\ncv_model.write.overwrite().save(prepend+\"model\")", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 1728:============================================>          (8 + 2) / 10]"}], "execution_count": 64}, {"cell_type": "markdown", "source": "# Dataset size\nWe now want to consider what happens when we expand the dataset from the top .001% of books to all books that have at least one rating", "metadata": {}}, {"cell_type": "code", "source": "//filter only to ensure that every book has at least 2 ratings and every user has rated at least two books\n//val top_percentile_books = df_merged.join(ratings_count,Seq(\"ISBN\",\"Book-Title\")).\n//filter($\"count\">book_quantile).\n//drop(\"count\")\n\nval full_dataset_books_filtered = df_unified.join(df_merged.groupBy(\"ISBN\").count(),Seq(\"ISBN\")).\n    filter($\"count\">1).\n    drop(\"count\")\nval full_dataset_users_filtered = full_dataset_books_filtered.\n    join(full_dataset_books_filtered.groupBy(\"User-ID\").count(),Seq(\"User-ID\")).\n    filter($\"count\">1).\n    drop(\"count\")\n    \nval temp_3 = full_dataset_users_filtered", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "full_dataset_books_filtered = [ISBN: string, User-ID: int ... 8 more fields]\nfull_dataset_users_filtered = [User-ID: int, ISBN: string ... 8 more fields]\ntemp_3 = [User-ID: int, ISBN: string ... 8 more fields]\n"}}, {"metadata": {}, "execution_count": 65, "output_type": "execute_result", "data": {"text/plain": "[User-ID: int, ISBN: string ... 8 more fields]"}}], "execution_count": 65}, {"cell_type": "code", "source": "val full_N = temp_3.select(\"User-ID\").distinct().count()\nprintln(\"The number of unique users is in the 'full' dataset is  %d\".format(full_N))\n\nval full_M = temp_3.select(\"ISBN\").distinct().count()\nprintln(\"The number of unique books in the 'full' dataset is %d\".format(full_M))\nprintln(\"The number of ratings in the 'full' dataset is %d\".format(temp_3.count()))", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The number of unique users is in the 'full' dataset is  24754                   ]\nThe number of unique books in the 'full' dataset is 49803                       ]\nThe number of ratings in the 'full' dataset is 250076                           ]\n"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "full_N = 24754\nfull_M = 49803\n"}}, {"metadata": {}, "execution_count": 66, "output_type": "execute_result", "data": {"text/plain": "49803"}}], "execution_count": 66}, {"cell_type": "code", "source": "val t5 = uid_indexer_fitted.transform(temp_3)\n\nval t6 = bid_indexer_fitted.transform(t5)\n\nval full_data = t6", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "t5 = [User-ID: int, ISBN: string ... 9 more fields]\nt6 = [User-ID: int, ISBN: string ... 10 more fields]\nfull_data = [User-ID: int, ISBN: string ... 10 more fields]\n"}}, {"metadata": {}, "execution_count": 67, "output_type": "execute_result", "data": {"text/plain": "[User-ID: int, ISBN: string ... 10 more fields]"}}], "execution_count": 67}, {"cell_type": "code", "source": "val Array(full_training, full_test) = full_data.select(model_cols.map(x=>col(x)):_*).randomSplit(Array(0.8, 0.2))", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "full_training = [uid: double, bid: double ... 1 more field]\nfull_test = [uid: double, bid: double ... 1 more field]\n"}}, {"metadata": {}, "execution_count": 68, "output_type": "execute_result", "data": {"text/plain": "[uid: double, bid: double ... 1 more field]"}}], "execution_count": 68}, {"cell_type": "code", "source": "val best_als = new ALS().\n    setMaxIter(10).\n    setUserCol(\"uid\").\n    setItemCol(\"bid\").\n    setRatingCol(\"Book-Rating\").\n    setColdStartStrategy(\"drop\").\n    setNonnegative(true)", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "best_als = als_4026c48a5a3b\n"}}, {"metadata": {}, "execution_count": 69, "output_type": "execute_result", "data": {"text/plain": "als_4026c48a5a3b"}}], "execution_count": 69}, {"cell_type": "code", "source": "val best_als_fitted = best_als.fit(full_training)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 1847:============================================>          (8 + 2) / 10]]"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "best_als_fitted = als_4026c48a5a3b\n"}}, {"metadata": {}, "execution_count": 70, "output_type": "execute_result", "data": {"text/plain": "als_4026c48a5a3b"}}], "execution_count": 70}, {"cell_type": "code", "source": "val full_predictions = best_als_fitted.transform(full_test)", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "full_predictions = [uid: double, bid: double ... 2 more fields]\n"}}, {"metadata": {}, "execution_count": 71, "output_type": "execute_result", "data": {"text/plain": "[uid: double, bid: double ... 2 more fields]"}}], "execution_count": 71}, {"cell_type": "code", "source": "val full_test_rmse = evaluator.evaluate(full_predictions)", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 1888:==================================================> (196 + 4) / 200]0]"}, {"metadata": {}, "output_type": "display_data", "data": {"text/plain": "full_test_rmse = 2.4238782074852407\n"}}, {"metadata": {}, "execution_count": 72, "output_type": "execute_result", "data": {"text/plain": "2.4238782074852407"}}], "execution_count": 72}, {"cell_type": "code", "source": "println(\"The RMSE for the test set for a model trained on the 'full' dataset is %f\".format(full_test_rmse))", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "The RMSE for the test set for a model trained on the 'full' dataset is 2.423878\n"}], "execution_count": 73}, {"cell_type": "code", "source": "evaluator.evaluate(best_als_fitted.transform(full_training))", "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[Stage 1929:===================================================>(198 + 2) / 200]0]"}, {"metadata": {}, "execution_count": 74, "output_type": "execute_result", "data": {"text/plain": "0.3862291077569126"}}], "execution_count": 74}, {"cell_type": "code", "source": "//sparsity calculation\nval total_possible_ratings = unique_users*unique_books*1.0\n\nval sparsity = (total_ratings/total_possible_ratings)*100", "metadata": {"trusted": true}, "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/plain": "total_possible_ratings = 1.4469629265E10\nsparsity = 0.002997112034162404\n"}}, {"metadata": {}, "execution_count": 75, "output_type": "execute_result", "data": {"text/plain": "0.002997112034162404"}}], "execution_count": 75}, {"cell_type": "markdown", "source": "# Conclusion", "metadata": {}}, {"cell_type": "markdown", "source": "Our models have not been able to outperform our baseline.  \n\nThe best performing model was an excplicit rating als with non negative constraints. \n\nOne reason for this may be the sparsity of this particular dataset. Collaborative filtering does not peform well on sparse datasets and the sparsity of the book-crossing dataset is .0029%\n\nIt may also be the case that they would benefit from better tuning of some of the parameters.\nThe large difference between the RMSE on training and test sets indicates that the algorithm is overfitting to the training set.  \n\nThe spark implementation is probably not worth it for this particular dataset.  \nThe baseline implementation achieves better results for a fraction of the computing resources and time.  \nA different recommender algorithm that includes other features about a book might be able to produce better recommendations. \n\nAs compared to the python implementation the spark one achieves better coverage since we are able to use more of the books from the dataset.  \n\nThe spark implementation whoever takes an incredibly long time to grid search parameters, there may be some optimizations or cluster configurations that would speed things up.  \nDespite how common parameter tuning is in other libraries like scikit-learn, most Spark ALS tutorials don;t do any parameter tuning. \n\nConsidering the poor performance and significant technical hurdles the spark option would only be viable for a model that needs to cover a large number of the items in the dataset and does not need a lot of tuning. ", "metadata": {}}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "outputs": [], "execution_count": null}]}